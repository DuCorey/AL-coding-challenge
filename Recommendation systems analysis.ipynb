{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9de8a1f",
   "metadata": {},
   "source": [
    "# Air Liquide coding challenge\n",
    "## Corey Ducharme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee3924",
   "metadata": {},
   "source": [
    "The coding challenge relates to the problem of recommendation systems. My understanding of the prompt is that I had to develop 2 algorithms for user movie recommendation using the movielens dataset. The first algorithm must be either a user-based method or an item-based neighborhood method. The second algorithm must be a matrix factorization collaborative filtering algorithm. Deliverable is the code contained in the following notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2014de9d",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f18d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "r = requests.get(\"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\", verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45690a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_zip = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "movie_zip.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106e42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc21e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(movie_zip.open('ml-latest-small/ratings.csv'))\n",
    "ratings_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fc1d50",
   "metadata": {},
   "source": [
    "Ratings for movies are done by users and are between 0 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(movie_zip.open('ml-latest-small/movies.csv'))\n",
    "movies_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8326429",
   "metadata": {},
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26540e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the base class for the recommer system\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class RecommenderSystem:\n",
    "    def __init__(self, ratings_df, movies_df):\n",
    "        self.ratings_df = ratings_df\n",
    "        self.movies_df = movies_df\n",
    "        \n",
    "        # Using a sparse representation to reduce memory usage\n",
    "        # However this slows downs indexing and other operations done on the dataframe significantly\n",
    "        user_movie_df = ratings_df.pivot(index = \"userId\", columns = \"movieId\", values = \"rating\").fillna(0)\n",
    "        self.user_movie_df = user_movie_df.astype(pd.SparseDtype(\"float\", 0))\n",
    "   \n",
    "    def recommend_movies(self, userid):\n",
    "        # Generic recommendation function that will be inherited by each different model\n",
    "        # Based on the models prediction this filters our the same movies and then \n",
    "        # prints them out nicely\n",
    "        user_row = userid - 1 # UserID starts at 1, not 0\n",
    "        user_predictions = self.predict(user_row)\n",
    "        \n",
    "        # Get the user's movie data for filtering\n",
    "        user_data = self.ratings_df[self.ratings_df.userId == (userid)]\n",
    "    \n",
    "        # Recommend the n highest predicted rating movies that the user hasn't seen yet.\n",
    "        recommendations = user_predictions[~user_predictions[\"movieId\"].isin(user_data[\"movieId\"])]\\\n",
    "            .sort_values(ascending=False, by=\"prediction\")\\\n",
    "            .head(5)\n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "    def recommend_movies_with_info(self, userid):\n",
    "        # Add movie info to the recommendations\n",
    "        # Recommendations are a DataFrame\n",
    "        return self.recommend_movies(userid).merge(self.movies_df, how=\"left\", left_on = \"movieId\", right_on = \"movieId\")\n",
    "    \n",
    "    def rmse(self):\n",
    "        return (((self.all_predictions() - self.user_movie_df)**2).sum().sum()/self.user_movie_df.size)**0.5   \n",
    "        \n",
    "    def mae(self):\n",
    "        return (self.all_predictions() - self.user_movie_df).abs().sum().sum()/self.user_movie_df.size\n",
    "    \n",
    "    def k_error(self, k):\n",
    "        # Return the error for a specified k parameter\n",
    "        self.fit(k)\n",
    "        return self.rmse()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basis of recommender systems is the user-movie interation matrix \"R\"\n",
    "rec = RecommenderSystem(ratings_df, movies_df)\n",
    "rec.user_movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.user_movie_df.sparse.density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28761f29",
   "metadata": {},
   "source": [
    "# Matrix factorization collaborative filtering recommender system\n",
    "## Collaborative filtering\n",
    "Collaborative filtering is a technique used by recommendation systems to make predictions of about the interest of a user based on collecting preferences from many users. Collaborative filtering creates a forecast for a rating for a product which an active user hasn’t rating yet, by building upon existing ratings of other users who have similar ratings as the active user.\n",
    "\n",
    "## Matrix factorization\n",
    "Matrix factorization are an unsupervised class of collaborative filtering algorithm where the user-item interaction matrix is decomposed into a lower dimensionality latent variable space. Matrix factorization models are a type of latent-factor model where users and products are rated on a set of latent variables. The matrix factorization method is well suited for tackling the issue of large sparse interaction matrices. \n",
    "\n",
    "### Singular Value Decomposition\n",
    "The most well known matrix factorization method is the Singular Value Decomposition (SVD). SVD is  a fast and efficient algorithm for identifying latent factors in data. \n",
    "\n",
    "$R = U \\Sigma V^T$\n",
    "\n",
    "In its simplest form, SVD decomposes a user-iteraction matrix $R$ into three components: $U$ the user features space matrix, $\\Sigma$ the diagonal matrix of singular values (weights), and $V^T$ the items features space matrix. $U$ represents how each “like” a feature and $V^t$ represents how each feature is relevant to each item. \n",
    "\n",
    "The SVD algorithm approximates the large user-item matrix into a lower rank by keeping only the k most important underlying features for both user and items. Predictions of SVD are simply the recombined approximated latent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our SVD class\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "class SVDrec(RecommenderSystem):\n",
    "    def fit(self, k):\n",
    "        self.U, sigma, self.Vt = svds(self.user_movie_df, k)\n",
    "        self.sigma = np.diag(sigma) # Convert sigma back into a diagonal matrix\n",
    "        \n",
    "    def all_predictions(self):\n",
    "        # We don't need to keep the predictions df. Since it is very large.\n",
    "        all_preds = self.U @ self.sigma @ self.Vt\n",
    "        all_preds_df = pd.DataFrame(all_preds, columns = self.user_movie_df.columns, index = self.user_movie_df.index)\n",
    "        return all_preds_df\n",
    "\n",
    "    def predict(self, user_row):\n",
    "        # Forecast the ratings for a specific user_row\n",
    "        # Since we didn't save all the predictions. We recalculate them as required predictions.\n",
    "        # Since this is matrix multiplication we can go fast by just multiplying the desired row at the begining\n",
    "        user_predictions = self.U[user_row,:] @ self.sigma @ self.Vt\n",
    "        user_predictions = pd.DataFrame(user_predictions, self.user_movie_df.columns)\\\n",
    "            .rename(columns={0: \"prediction\"})\\\n",
    "            .reset_index(inplace=False)\n",
    "        return user_predictions\n",
    "    \n",
    "    def out_of_sample_pred(self, user_row):\n",
    "        # Fit the model on in-sample data\n",
    "        self.U, sigma, self.Vt = svds(self.train, k)\n",
    "        self.sigma = np.diag(sigma) # Convert sigma back into a diagonal matrix\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_rec = SVDrec(ratings_df, movies_df)\n",
    "svd_rec.fit(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_rec.all_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fae081",
   "metadata": {},
   "outputs": [],
   "source": [
    "(svd_rec.all_predictions() - svd_rec.user_movie_df).abs().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f84f6a",
   "metadata": {},
   "source": [
    "This gives the predictions for all users and for all movies in the dataset. A better forecast would be the top N movies for a specific user that he hasn't seen yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2931d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_rec.recommend_movies_with_info(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb190df",
   "metadata": {},
   "source": [
    "# User-based KNN recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01a12c8",
   "metadata": {},
   "source": [
    "K-NN recommender systems are derived for the nearest neighbors method. They determine the predicted score by looking at what the most similar users have also recommended for the item.\n",
    "\n",
    "The predicted for an item that a user hasn't seen is the average rating of users which are closest to our user normlized by the distance.\n",
    "\n",
    "$\\hat{r}_{ui} = \\frac{\\sum sim(u,v) \\cdot r_{vi}}{\\sum sim(u,v)}$\n",
    "Here, u is the user, i the item, v other users which are our neighbor and r the recommendation. The sum is done over all k neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e86859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "class KNNrec(RecommenderSystem):\n",
    "    def fit(self, k):        \n",
    "        # Cosine distance is 1 - cosine similarity.\n",
    "        # We want the similarity for our clustering\n",
    "        self.distmat = 1 - cosine_distances(self.user_movie_df)\n",
    "        self.k = k\n",
    "        # Unfortunately pandas sparse is really slow for indexing which is necessary \n",
    "        # to predict with it. Converting it back to dense format.\n",
    "        # TODO Would need to be looked at later for larger datasets\n",
    "        if pd.api.types.is_sparse(self.user_movie_df[1]):\n",
    "            self.user_movie_df = self.user_movie_df.sparse.to_dense()\n",
    "        \n",
    "    def nearest_neighbors(self, i):\n",
    "        # Return the index of the nearest neighbors excluding yourself\n",
    "        return np.argsort(self.distmat[i])[::-1][1:self.k+1]\n",
    "    \n",
    "    def predict_internal(self, i):\n",
    "        neighbors = self.nearest_neighbors(i)\n",
    "        k = self.k\n",
    "        prediction = sum([self.user_movie_df.iloc[id]*self.distmat[k, id] for id in neighbors])\\\n",
    "            /sum([self.distmat[k,id] for id in neighbors])\n",
    "        return prediction\n",
    "    \n",
    "    def predict(self, i):\n",
    "        user_predictions = pd.DataFrame(self.predict_internal(i))\\\n",
    "            .rename(columns={0: \"prediction\"})\\\n",
    "            .reset_index(inplace=False)\n",
    "        return(user_predictions)\n",
    "    \n",
    "    def all_predictions(self):\n",
    "        all_preds = [self.predict_internal(user) for user in np.arange(0,len(self.user_movie_df),1)]\n",
    "        all_preds = pd.DataFrame(all_preds, index = self.user_movie_df.index)\n",
    "        return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_rec = KNNrec(ratings_df, movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_rec.fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_rec.all_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e887e1",
   "metadata": {},
   "source": [
    "This gives the predictions for all users and for all movies in the dataset. A individual forcast would be the top N movies for a specific user that he hasn't seen yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237d8c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_rec.recommend_movies_with_info(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0588bc",
   "metadata": {},
   "source": [
    "# Performance comparison\n",
    "\n",
    "Measuring the performance of recommender systems is a difficult problem in and of itself. Numerous error measurement exists and they vary depending on the class of recommnder systems. Furthermore, error measurements should be tailored to the industrial use case. No metric is better than how real customers interact with recommendations produced in the real world.\n",
    "\n",
    "In the work above, both methods used can be considered as user-based. They use other users information to predict the ratings for a new user. This allows us to compare them directly on those predictions. \n",
    "\n",
    "We chose to use the common RMSE between the predicted ratings and the real ratings.\n",
    "\n",
    "Choosing an error measurement allows us to optimize the models on a training sample. Both methods have a hyperparameter which we can iterate over to determine the optimal value. \n",
    "\n",
    "For SVD, the hyperparameter is the number of features kept in the lower ranks.\n",
    "\n",
    "For KNN, the hyperparameter is the number of clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab90807",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_errors = [svd_rec.k_error(k) for k in np.arange(1,100, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e25361",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_error = [knn_rec.k_error(k) for k in np.arange(1,100, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff7ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(x = np.arange(1,100, 5), y = [svd_errors, knn_error])\n",
    "fig.data[0].name = \"SVD\"\n",
    "fig.data[1].name = \"KNN\"\n",
    "\n",
    "fig.update_layout(yaxis_title='RMSE', xaxis_title = 'k')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d00703",
   "metadata": {},
   "source": [
    "The in-sample error of the SVD model will only decrease as k increases. A more thorough evaluation of the error is required to evaluate the models, i.e. creating train, validation and test datasets. Which would allow us to determine the best k which does not overfit the data. This same procedure can be repeated for the KNN method. Although one can determine a robust value of k on training data only.\n",
    "\n",
    "Since both SVD and KNN are user-based, they both suffer from the cold start problem. If a user has no history, he cannot be linked to other users and thus no recommendation can be made. In these cases, I the use of item-based recommendation systems is recommended. KNN can be easily adapted to item-based recommendations. Item-based recommendations will exclusively determine a recommendation for a product based on similarity of the product to others. \n",
    "\n",
    "The debate between the superiority of user- vs item- based recommender systems has led to the more modern approach of using a combined multi-criteria recommender system which can combine both user and item based methods when performing recommendations. Furthermore, one can and should include any business specific parameters and needs to the recommender systems being developped."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
